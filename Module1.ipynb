{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMqrXB8ZRufLO7bSF2qsI7F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aakaey181/RA_Porject_ML1/blob/main/Module1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Module 1 of 3: Automating Image Data Collection & Preprocessing** - *Collect and prepare potholes vs. clean road” images using the DuckDuckGo API for end-to-end ML pipelines*\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "qGsGp_JazZb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Introduction** <br>\n",
        "This module walks through the first steps of an end-to-end machine learning workflow: collecting image data from the web using a programmatic API and preparing it for model training. You’ll learn how to automate bulk downloads of road with potholes vs. common road without potholes images via the DuckDuckGo Image Search API, organize them into a clear folder structure, and apply basic cleaning and resizing so that any standard deep-learning library can ingest the data with minimal fuss. <br>\n",
        "\n",
        "Following the existing notebook, we’ll:\n",
        "\n",
        "- Mount and configure the environment (Google Drive, dependencies, imports).\n",
        "\n",
        "- Download images automatically via the DuckDuckGo Image Search API.\n",
        "\n",
        "- Organize files into positive and negative sample folders.\n",
        "\n",
        "- Clean the dataset, removing corrupted files and ensuring consistent labeling.\n",
        "\n",
        "- Build a tf.data.Dataset pipeline for efficient batching and preprocessing.\n",
        "\n",
        "By the end of this module, you’ll have a clean, folder-structured dataset ready for model training in Module 2.\n",
        "\n",
        "<br>\n"
      ],
      "metadata": {
        "id": "LIMf5mS6iEew"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Environment Setup and Data Collection**\n",
        "\n"
      ],
      "metadata": {
        "id": "YeyvlJXXozqB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.0 Basic Setup"
      ],
      "metadata": {
        "id": "UMC4bmw5l7iH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount Google Drive to access and persist your data:"
      ],
      "metadata": {
        "id": "GZ_mPdob5xzf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "zXW3Ugag5xe-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00c47adb-6197-4b39-d874-48c93d398d98"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing Dependencies in a New Environment: <br>\n",
        "When you work in a new environment, it is important to install all the necessary dependencies before running your code. In Google Colab, we use the !pip install command to install Python packages directly from a notebook cell. This ensures that all the required libraries are available for this notebook.\n",
        "\n",
        "Here are the key packages will be needed in this notebook:"
      ],
      "metadata": {
        "id": "OCbIkysuvsqT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy pandas matplotlib\n",
        "!pip install scikit-learn\n",
        "!pip install tensorflow\n",
        "!pip install tensorflow-addons\n",
        "!pip install duckduckgo-search"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qb6yrnHisNQa",
        "outputId": "88715e75-62fb-45d9-8370-4c93942b22ce"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow-addons) (24.2)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "Downloading tensorflow_addons-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "  Attempting uninstall: typeguard\n",
            "    Found existing installation: typeguard 4.4.2\n",
            "    Uninstalling typeguard-4.4.2:\n",
            "      Successfully uninstalled typeguard-4.4.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "inflect 7.5.0 requires typeguard>=4.0.1, but you have typeguard 2.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tensorflow-addons-0.23.0 typeguard-2.13.3\n",
            "Collecting duckduckgo-search\n",
            "  Downloading duckduckgo_search-8.0.2-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from duckduckgo-search) (8.2.0)\n",
            "Collecting primp>=0.15.0 (from duckduckgo-search)\n",
            "  Downloading primp-0.15.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: lxml>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from duckduckgo-search) (5.4.0)\n",
            "Downloading duckduckgo_search-8.0.2-py3-none-any.whl (18 kB)\n",
            "Downloading primp-0.15.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: primp, duckduckgo-search\n",
            "Successfully installed duckduckgo-search-8.0.2 primp-0.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Libraries: <br>\n",
        "Import libraries such as requests, os, shutil, random, and TensorFlow/Keras components."
      ],
      "metadata": {
        "id": "Xhdxpwex59q6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "import time\n",
        "import shutil\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from duckduckgo_search import DDGS"
      ],
      "metadata": {
        "id": "EiEhlVVwh3PD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Dataset Directory Setup"
      ],
      "metadata": {
        "id": "Qu-ovDm0m42_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Base directory (where images will be saved)\n",
        "BASE_DATA_DIR = \"drive/MyDrive/ra/data\"\n",
        "RAW_IMAGE_DIR = os.path.join(BASE_DATA_DIR, \"raw_images\")\n",
        "os.makedirs(RAW_IMAGE_DIR, exist_ok=True)"
      ],
      "metadata": {
        "id": "AadlLZMBh30g"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This lets subsequent steps target each class by name."
      ],
      "metadata": {
        "id": "S_ZdE2Peizn2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 Image Downloading and Processing Logic\n",
        "We begin by collecting images for both classes:\n",
        "\n",
        "- Positive class: road images with potholes\n",
        "\n",
        "- Negative class: road images without potholes (e.g., roads, highways, etc.)\n",
        "\n",
        "A custom web-scraping script using the DuckDuckGo API downloads images and saves them to our Google Drive. Negative samples from various road-related queries are merged into a unified folder (e.g. road_without_potholes). We provide you a helper function to scrape and save images:"
      ],
      "metadata": {
        "id": "xRBNOajt6GGG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def download_images(search_query, num_images=10, save_dir=RAW_IMAGE_DIR):\n",
        "    \"\"\"\n",
        "    Downloads images from DuckDuckGo Image Search.\n",
        "\n",
        "    Parameters:\n",
        "    - search_query: (str) The search keyword (e.g., \"zebra crossing\" or \"random street without zebra crossing\").\n",
        "    - num_images: (int) Number of images to download.\n",
        "    - save_dir: (str) Directory where images will be stored.\n",
        "    \"\"\"\n",
        "    # Create a folder for the search category\n",
        "    category_dir = os.path.join(save_dir, search_query.replace(\" \", \"_\"))\n",
        "    os.makedirs(category_dir, exist_ok=True)\n",
        "\n",
        "    print(f\"Searching for {num_images} images of '{search_query}'...\")\n",
        "    with DDGS() as ddgs:\n",
        "        # Request more images than needed to filter out invalid ones\n",
        "        image_results = ddgs.images(search_query, max_results=num_images * 2)\n",
        "\n",
        "    downloaded = 0\n",
        "    seen_urls = set()  # To avoid duplicate downloads\n",
        "\n",
        "    for i, result in enumerate(image_results):\n",
        "        url = result[\"image\"]\n",
        "        if url in seen_urls:\n",
        "            continue\n",
        "        seen_urls.add(url)\n",
        "\n",
        "        try:\n",
        "            response = requests.get(url, timeout=10)\n",
        "            if response.status_code == 200:\n",
        "                # Save image to file\n",
        "                file_path = os.path.join(category_dir, f\"{search_query.replace(' ', '_')}_{i}.jpg\")\n",
        "                with open(file_path, \"wb\") as f:\n",
        "                    f.write(response.content)\n",
        "                downloaded += 1\n",
        "                print(f\"Downloaded: {file_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to download {url}: {e}\")\n",
        "\n",
        "        # Stop when enough images are downloaded\n",
        "        if downloaded >= num_images:\n",
        "            break\n",
        "\n",
        "        time.sleep(1)  # Delay to avoid getting blocked\n",
        "\n",
        "    print(f\"Successfully downloaded {downloaded}/{num_images} images for '{search_query}' in {category_dir}\")"
      ],
      "metadata": {
        "id": "xDG89333Cpj0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**: If your target changes (e.g., detecting zebra crossings instead of potholes), replace the query string 'potholes' with 'zebra crossing'. Then uncomment or adjust the corresponding `download_images(...)` call to fetch the appropriate images.\n",
        "\n",
        "**Class Balance Reminder**: Keep positive and negative examples roughly equal (e.g., you may try 100 each, total 200) to help your model learn both classes effectively.\n",
        "\n",
        "Positive samples: `download_images('potholes', 100)` <br>\n",
        "Negative samples: run with queries like 'road', 'highway', then merge subfolders into road_without_potholes/ using shutil.move. (next step)<br>\n",
        "\n"
      ],
      "metadata": {
        "id": "6dnS5J2djaFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO:\n",
        "# Download Positive class: images with potholes\n",
        "# Uncomment the following line of code\n",
        "# download_images(\"potholes\", num_images=100)\n",
        "\n",
        "\n",
        "# TODO:\n",
        "# Download Negative class: images without potholes\n",
        "# Uncomment the following line of code\n",
        "# download_images(\"road\", num_images = 20)\n",
        "# download_images(\"highway\", num_images = 20)\n",
        "# download_images(\"county road\", num_images = 20)\n",
        "# download_images(\"rural road\", num_images = 20)\n",
        "# download_images(\"empty road\", num_images = 20)"
      ],
      "metadata": {
        "id": "Cgp0W0mXDOR0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcced49d-c682-4a7e-b30e-207d99b4fffd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Searching for 40 images of 'rural road'...\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/rural_road/rural_road_6.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/rural_road/rural_road_8.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/rural_road/rural_road_9.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/rural_road/rural_road_10.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/rural_road/rural_road_14.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/rural_road/rural_road_15.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/rural_road/rural_road_16.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/rural_road/rural_road_17.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/rural_road/rural_road_18.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/rural_road/rural_road_19.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/rural_road/rural_road_20.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/rural_road/rural_road_21.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/rural_road/rural_road_22.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/rural_road/rural_road_23.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/rural_road/rural_road_24.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/rural_road/rural_road_25.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/rural_road/rural_road_26.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/rural_road/rural_road_27.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/rural_road/rural_road_28.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/rural_road/rural_road_29.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/rural_road/rural_road_30.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/rural_road/rural_road_32.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/rural_road/rural_road_33.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/rural_road/rural_road_34.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/rural_road/rural_road_35.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/rural_road/rural_road_36.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/rural_road/rural_road_37.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/rural_road/rural_road_38.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/rural_road/rural_road_39.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/rural_road/rural_road_40.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/rural_road/rural_road_41.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/rural_road/rural_road_42.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/rural_road/rural_road_43.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/rural_road/rural_road_44.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/rural_road/rural_road_45.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/rural_road/rural_road_46.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/rural_road/rural_road_47.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/rural_road/rural_road_48.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/rural_road/rural_road_49.jpg\n",
            "Failed to download http://www.joecarey.ie/wp-content/uploads/2023/02/Rural-road.jpg: HTTPConnectionPool(host='www.joecarey.ie', port=80): Max retries exceeded with url: /wp-content/uploads/2023/02/Rural-road.jpg (Caused by NameResolutionError(\"<urllib3.connection.HTTPConnection object at 0x79badf476fd0>: Failed to resolve 'www.joecarey.ie' ([Errno -2] Name or service not known)\"))\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/rural_road/rural_road_51.jpg\n",
            "Successfully downloaded 40/40 images for 'rural road' in drive/MyDrive/ra/data/raw_images/rural_road\n",
            "Searching for 40 images of 'empty road'...\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/empty_road/empty_road_0.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/empty_road/empty_road_1.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/empty_road/empty_road_3.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/empty_road/empty_road_4.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/empty_road/empty_road_5.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/empty_road/empty_road_6.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/empty_road/empty_road_7.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/empty_road/empty_road_8.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/empty_road/empty_road_9.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/empty_road/empty_road_10.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/empty_road/empty_road_11.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/empty_road/empty_road_12.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/empty_road/empty_road_14.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/empty_road/empty_road_15.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/empty_road/empty_road_16.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/empty_road/empty_road_17.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/empty_road/empty_road_18.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/empty_road/empty_road_19.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/empty_road/empty_road_20.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/empty_road/empty_road_21.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/empty_road/empty_road_23.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/empty_road/empty_road_24.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/empty_road/empty_road_26.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/empty_road/empty_road_27.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/empty_road/empty_road_28.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/empty_road/empty_road_29.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/empty_road/empty_road_30.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/empty_road/empty_road_31.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/empty_road/empty_road_32.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/empty_road/empty_road_33.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/empty_road/empty_road_35.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/empty_road/empty_road_36.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/empty_road/empty_road_37.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/empty_road/empty_road_38.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/empty_road/empty_road_39.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/empty_road/empty_road_40.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/empty_road/empty_road_41.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/empty_road/empty_road_42.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/empty_road/empty_road_43.jpg\n",
            "Downloaded: drive/MyDrive/ra/data/raw_images/empty_road/empty_road_44.jpg\n",
            "Successfully downloaded 40/40 images for 'empty road' in drive/MyDrive/ra/data/raw_images/empty_road\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The folder structure will be:<br>\n",
        "\n",
        "```plaintext\n",
        "data\n",
        "├── raw_images/\n",
        "│   └── potholes/\n",
        "│   └── road/\n",
        "│   └── highway/\n",
        "│   └── .../\n",
        "\n"
      ],
      "metadata": {
        "id": "PPpAGb56toVz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: Negative class queries (`neg_queries`):\n",
        "#    - Edit the `neg_queries = [...]` list to include keywords for images **without** your target.\n",
        "#    - For potholes: `neg_queries = [\"road\", \"highway\", \"county road\", \"rural road\", \"empty road\"]`.\n",
        "# You can\n",
        "neg_queries = [\"road\", \"highway\", \"county road\", \"rural road\", \"empty road\"]\n",
        "\n",
        "#TODO:  Negative folder naming (`NEG_FOLDER_NAME`):\n",
        "#    - Use `road_without_<target>` format. E.g., `NEG_FOLDER_NAME = \"road_without_potholes\"`.\n",
        "#    - For zebra crossings, use `NEG_FOLDER_NAME = \"road_without_zebra_crossing\"`.\n",
        "NEG_FOLDER_NAME = \"road_without_potholes\"\n",
        "\n",
        "common_neg_folder = os.path.join(BASE_DATA_DIR, \"raw_images\", NEG_FOLDER_NAME)\n",
        "os.makedirs(common_neg_folder, exist_ok=True)\n",
        "\n",
        "for query in neg_queries:\n",
        "    src_folder = os.path.join(BASE_DATA_DIR, \"raw_images\", query.replace(\" \", \"_\"))\n",
        "    if os.path.exists(src_folder):\n",
        "        for file in os.listdir(src_folder):\n",
        "            src_file = os.path.join(src_folder, file)\n",
        "            dst_file = os.path.join(common_neg_folder, file)\n",
        "            shutil.move(src_file, dst_file)\n",
        "        os.rmdir(src_folder)\n",
        "\n",
        "print(\"combine negative sample to：\", common_neg_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpudyVXCEMfR",
        "outputId": "7fc69048-b473-4c31-e5b7-0d68f0cbc591"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "combine negative sample to： drive/MyDrive/ra/data/raw_images/road_without_potholes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3 Data Cleaning <br>\n",
        "After downloading, check for and remove files with invalid extensions or corrupted images. For example, iterate through the image file list, attempt to decode each file using TensorFlow functions, and delete any that fail to decode. Finally, print the number of valid images remaining.\n",
        "\n",
        "-  Suppose `RAW_IMAGE_DIR` has two subfolders: `potholes`  (positive class) & `road_without_potholes` (negative class). We will read them all into arrays."
      ],
      "metadata": {
        "id": "YDmht3q_iRyj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.3.1 Class discovery and labeling"
      ],
      "metadata": {
        "id": "drwDWWyrr6X7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensure a clear folder structure under raw_images/: <br>\n",
        "raw_images/ <br>\n",
        "  ├── potholes/       # positive samples <br>\n",
        "  └── road_without_potholes/    # negative samples <br>"
      ],
      "metadata": {
        "id": "HKDA7OuTiXKO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Set TARGET to the object you want to detect.\n",
        "#       e.g. TARGET = \"potholes\"         → folders “potholes” & “road_without_potholes”\n",
        "#            TARGET = \"zebra_crossing\"   → folders “road_zebra_crossing” & “road_without_zebra_crossing”\n",
        "# pos_pattern and neg_pattern are built from TARGET;\n",
        "# make sure exactly one folder matches each before moving on.\n",
        "TARGET = \"potholes\"\n",
        "\n",
        "pos_pattern = f\"{TARGET}\"\n",
        "neg_pattern = f\"road_without_{TARGET}\"\n",
        "\n",
        "all_folders = os.listdir(RAW_IMAGE_DIR)\n",
        "pos_folders = [f for f in all_folders if f == pos_pattern]\n",
        "neg_folders = [f for f in all_folders if f == neg_pattern]\n",
        "\n",
        "if len(pos_folders) != 1 or len(neg_folders) != 1:\n",
        "    raise ValueError(\n",
        "        f\"Expect one pos folder matching '{pos_pattern}' and one neg matching '{neg_pattern}'.\\n\"\n",
        "        f\"Found pos: {pos_folders}, neg: {neg_folders}\"\n",
        "    )\n",
        "\n",
        "class_names = pos_folders + neg_folders\n",
        "print(\"Classes found:\", class_names)\n",
        "\n",
        "file_paths, labels = [], []\n",
        "for cls_name in class_names:\n",
        "    cls_folder = os.path.join(RAW_IMAGE_DIR, cls_name)\n",
        "    label = 1 if cls_name in pos_folders else 0\n",
        "    for fname in os.listdir(cls_folder):\n",
        "        file_paths.append(os.path.join(cls_folder, fname))\n",
        "        labels.append(label)\n",
        "\n",
        "file_paths = np.array(file_paths)\n",
        "labels     = np.array(labels)\n",
        "\n",
        "print(f\"Total {TARGET} images:\", len(file_paths),\n",
        "      \"| positives:\", int(labels.sum()), \"negatives:\", int(len(labels)-labels.sum()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_jrllkgLwo6",
        "outputId": "f87da16f-fc75-4467-ee54-a3994a8b1f1c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes found: ['potholes', 'road_without_potholes']\n",
            "Total potholes images: 428 | positives: 228 negatives: 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.3.2 Remove Corrupted Files: <br>\n",
        "Iterate through all file paths, check if they are valid images (using extensions and TensorFlow’s decoding functions), print details when a file is removed, and update our list of file paths."
      ],
      "metadata": {
        "id": "_seDxw1skv_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check & remove corrupted files\n",
        "def check_corrupt(path):\n",
        "    try:\n",
        "        data = tf.io.read_file(path)\n",
        "        _ = tf.image.decode_jpeg(data, channels=3)\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Corrupted file removed: {path} - Error: {e}\")\n",
        "        os.remove(path)\n",
        "        return False\n",
        "\n",
        "final_paths = []\n",
        "final_labels = []\n",
        "for p, l in zip(file_paths, labels):\n",
        "    if check_corrupt(p):\n",
        "        final_paths.append(p)\n",
        "        final_labels.append(l)\n",
        "\n",
        "file_paths = np.array(final_paths)\n",
        "labels = np.array(final_labels)\n",
        "print(\"After removing corrupted files:\", len(file_paths))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dORWrAKYjGqI",
        "outputId": "9e45e8e4-cc31-40d3-b1c8-5a3422c0910f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corrupted file removed: drive/MyDrive/ra/data/raw_images/potholes/potholes_3.jpg - Error: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required. [Op:DecodeJpeg]\n",
            "Corrupted file removed: drive/MyDrive/ra/data/raw_images/potholes/potholes_6.jpg - Error: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required. [Op:DecodeJpeg]\n",
            "Corrupted file removed: drive/MyDrive/ra/data/raw_images/potholes/potholes_9.jpg - Error: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required. [Op:DecodeJpeg]\n",
            "Corrupted file removed: drive/MyDrive/ra/data/raw_images/potholes/potholes_13.jpg - Error: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required. [Op:DecodeJpeg]\n",
            "Corrupted file removed: drive/MyDrive/ra/data/raw_images/potholes/potholes_20.jpg - Error: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required. [Op:DecodeJpeg]\n",
            "Corrupted file removed: drive/MyDrive/ra/data/raw_images/potholes/potholes_35.jpg - Error: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required. [Op:DecodeJpeg]\n",
            "Corrupted file removed: drive/MyDrive/ra/data/raw_images/potholes/potholes_72.jpg - Error: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required. [Op:DecodeJpeg]\n",
            "Corrupted file removed: drive/MyDrive/ra/data/raw_images/potholes/potholes_135.jpg - Error: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required. [Op:DecodeJpeg]\n",
            "Corrupted file removed: drive/MyDrive/ra/data/raw_images/potholes/potholes_179.jpg - Error: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required. [Op:DecodeJpeg]\n",
            "Corrupted file removed: drive/MyDrive/ra/data/raw_images/potholes/potholes_191.jpg - Error: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required. [Op:DecodeJpeg]\n",
            "Corrupted file removed: drive/MyDrive/ra/data/raw_images/potholes/potholes_158.jpg - Error: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required. [Op:DecodeJpeg]\n",
            "Corrupted file removed: drive/MyDrive/ra/data/raw_images/potholes/potholes_226.jpg - Error: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required. [Op:DecodeJpeg]\n",
            "Corrupted file removed: drive/MyDrive/ra/data/raw_images/potholes/potholes_235.jpg - Error: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required. [Op:DecodeJpeg]\n",
            "Corrupted file removed: drive/MyDrive/ra/data/raw_images/road_without_potholes/road_5.jpg - Error: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required. [Op:DecodeJpeg]\n",
            "Corrupted file removed: drive/MyDrive/ra/data/raw_images/road_without_potholes/road_29.jpg - Error: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required. [Op:DecodeJpeg]\n",
            "Corrupted file removed: drive/MyDrive/ra/data/raw_images/road_without_potholes/road_35.jpg - Error: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required. [Op:DecodeJpeg]\n",
            "Corrupted file removed: drive/MyDrive/ra/data/raw_images/road_without_potholes/road_40.jpg - Error: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required. [Op:DecodeJpeg]\n",
            "Corrupted file removed: drive/MyDrive/ra/data/raw_images/road_without_potholes/highway_8.jpg - Error: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required. [Op:DecodeJpeg]\n",
            "Corrupted file removed: drive/MyDrive/ra/data/raw_images/road_without_potholes/highway_41.jpg - Error: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required. [Op:DecodeJpeg]\n",
            "Corrupted file removed: drive/MyDrive/ra/data/raw_images/road_without_potholes/county_road_15.jpg - Error: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required. [Op:DecodeJpeg]\n",
            "After removing corrupted files: 408\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# You might need to check again the size of classes\n",
        "print(f\"Total {TARGET} images:\", len(file_paths),\n",
        "      \"| positives:\", int(labels.sum()), \"negatives:\", int(len(labels)-labels.sum()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5urzfZzsNy0",
        "outputId": "16d6d6e6-0c1a-4b10-c655-1542f81cfd21"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total potholes images: 408 | positives: 215 negatives: 193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.4 Wrapping Up Module 1 and Create Dataset Using tf.data.Dataset <br>"
      ],
      "metadata": {
        "id": "dtlCac77jcQH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "At the end of this module, we encapsulate all the file-path and label handling and other helper function into a single utils script. In Module 2 you’ll import and call this `create_dataset(...)` function directly—so you can jump straight into building and training your model without repeating the setup steps."
      ],
      "metadata": {
        "id": "6wN2D2577KSF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "please run the following code before move to module 2"
      ],
      "metadata": {
        "id": "UB8GP7HBySWP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/drive/MyDrive/ra/ml_utils.py\n",
        "import os, time, random, shutil, requests, numpy as np, tensorflow as tf\n",
        "# from duckduckgo_search import DDGS\n",
        "import tensorflow.keras.applications.mobilenet_v2 as mobilenet_v2\n",
        "\n",
        "IMG_SIZE   = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "def load_and_preprocess(path, label):\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, IMG_SIZE)\n",
        "    img = mobilenet_v2.preprocess_input(img)\n",
        "    return img, label\n",
        "\n",
        "def create_dataset(paths, labs):\n",
        "    ds = tf.data.Dataset.from_tensor_slices((paths, labs))\n",
        "    ds = ds.map(load_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    ds = ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "    return ds\n"
      ],
      "metadata": {
        "id": "fLH4Ga-WjUY-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fb946f7-1b99-48a5-8e31-a69b54ce310a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/drive/MyDrive/ra/ml_utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify it really is a plain file\n",
        "!file /content/drive/MyDrive/ra/ml_utils.py\n",
        "!head -n 3 /content/drive/MyDrive/ra/ml_utils.py"
      ],
      "metadata": {
        "id": "3Yf_pGRgyUC2",
        "outputId": "0f3edebb-ed15-4f1f-8168-30dae9fe1ac3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ra/ml_utils.py: Python script, ASCII text executable\n",
            "import os, time, random, shutil, requests, numpy as np, tensorflow as tf\n",
            "# from duckduckgo_search import DDGS\n",
            "import tensorflow.keras.applications.mobilenet_v2 as mobilenet_v2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mFm0qGDbspp8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}